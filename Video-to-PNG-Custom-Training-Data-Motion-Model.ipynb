{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec  7 15:34:11 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    39W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "base_path = str(Path.home())\n",
    "print(base_path)\n",
    "\n",
    "# Check if running in Colab or AWS.\n",
    "#\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available bucket (0): deep-learning-datasets-bucket\n",
      "Available bucket (1): detectron2-models-bucket\n",
      "Available bucket (2): gan-models-bucket\n",
      "Available bucket (3): insightface-models-bucket\n",
      "Available bucket (4): motion-models\n",
      "\n",
      "Displaying bucket:  motion-models\n",
      "2020-11-03 05:06:42    0 Bytes first-order-model/\n",
      "2020-11-03 05:06:57    0 Bytes first-order-model/pytorch/\n",
      "2020-11-17 15:28:56    0 Bytes first-order-model/pytorch/.ipynb_checkpoints/\n",
      "2020-11-17 15:47:57    0 Bytes first-order-model/pytorch/log.txt\n",
      "2020-11-17 15:47:55    0 Bytes first-order-model/pytorch/train-vis/\n",
      "2020-11-17 15:47:42    1.7 KiB first-order-model/pytorch/vox-256-finetune.yaml\n",
      "2020-11-03 05:10:01  716.1 MiB first-order-model/pytorch/vox-adv-cpk.pth.tar\n",
      "2020-11-03 05:18:31  695.0 MiB first-order-model/pytorch/vox-cpk.pth.tar\n",
      "2020-11-11 04:16:23    0 Bytes motion-cosegmentation/\n",
      "2020-11-11 04:16:39    0 Bytes motion-cosegmentation/pytorch/\n",
      "2020-11-11 04:18:57  716.3 MiB motion-cosegmentation/pytorch/taichi-10segments.pth.tar\n",
      "2020-11-11 04:18:57  716.4 MiB motion-cosegmentation/pytorch/vox-10segments.pth.tar\n",
      "2020-11-11 04:18:57  696.6 MiB motion-cosegmentation/pytorch/vox-15segments.pth.tar\n",
      "2020-11-11 04:18:57  694.0 MiB motion-cosegmentation/pytorch/vox-5segments.pth.tar\n",
      "\n",
      "Total Objects: 14\n",
      "   Total Size: 4.1 GiB\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# List available buckets\n",
    "#\n",
    "available_buckets = []\n",
    "s3 = boto3.resource('s3')\n",
    "for idx, bucket in enumerate(s3.buckets.all()):\n",
    "    print(\"Available bucket (%d): %s\" % (idx, bucket.name))\n",
    "    available_buckets.append(bucket.name)\n",
    "\n",
    "# Interested in bucket with pre-trained models.\n",
    "#\n",
    "bucket_name = available_buckets[4]\n",
    "print(\"\\nDisplaying bucket: \", bucket_name)\n",
    "\n",
    "!aws s3 ls s3://$bucket_name --recursive --human-readable --summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounting bucket:  motion-models\n",
      "path to model:  /home/jupyter/pretrained_models_motion/vox-cpk.pth.tar\n"
     ]
    }
   ],
   "source": [
    "# Create a directory and mount bucket.\n",
    "#\n",
    "print(\"Mounting bucket: \", bucket_name)\n",
    "\n",
    "local_path_to_motion_weights_dir = f'{base_path}/pretrained_models_motion' \n",
    "!mkdir -p $local_path_to_motion_weights_dir\n",
    "\n",
    "model_to_mount = '/first-order-model/pytorch'\n",
    "model_name = 'vox-cpk.pth.tar'\n",
    "path_motion_weights = f'{local_path_to_motion_weights_dir}/{model_name}'\n",
    "\n",
    "print(\"path to model: \", path_motion_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getuid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket mounted to: /home/jstaley/pretrained_models_motion_v2\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    !s3fs motion-models:/first-order-model/pytorch /content/pretrained_models_motion -o passwd_file=${HOME}/.passwd-s3fs -o umask=0277,uid=0\n",
    "    print(\"Bucket mounted to: /content/pretrained_models_motion\")\n",
    "else:\n",
    "    # AWS\n",
    "    #\n",
    "    # !s3fs gan-models-bucket:/pixel2style2pixel/pytorch /home/ubuntu/pretrained_models_p2p -o passwd_file=${HOME}/.passwd-s3fs -o umask=0277,uid=1000\n",
    "    # print(\"Bucket mounted to: /home/ubuntu/pretrained_models_p2p\")\n",
    "    \n",
    "    # GCP\n",
    "    #\n",
    "    !s3fs motion-models:/first-order-model/pytorch /home/jupyter/pretrained_models_motion -o passwd_file=${HOME}/.passwd-s3fs -o umask=0777,uid=1000\n",
    "    print(\"Bucket mounted to: /home/jstaley/pretrained_models_motion\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the training data (i.e. movie clip) and save to PNGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(path, frames, format):\n",
    "    if format == '.mp4':\n",
    "        imageio.mimsave(path, frames)\n",
    "    elif format == '.png':\n",
    "        if os.path.exists(path):\n",
    "            print (\"Warning: skipping video %s\" % os.path.basename(path))\n",
    "            return\n",
    "        else:\n",
    "            os.makedirs(path)\n",
    "        for j, frame in enumerate(frames):\n",
    "            imageio.imsave(os.path.join(path, str(j).zfill(7) + '.png'), frames[j]) \n",
    "    else:\n",
    "        print (\"Unknown format %s\" % format)\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving frames to:  /home/jstaley/assets/pngs_256px/train/id0002#11111111#000000#000000.mp4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving frames to:  /home/jstaley/assets/pngs_256px/train/id0002#22222222#000000#000000.mp4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving frames to:  /home/jstaley/assets/pngs_256px/train/id0002#33333333#000000#000000.mp4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in terminal\n",
    "# NOTE:\n",
    "# - Assumes config/vox-XXX.yaml has been appropriately updated/written\n",
    "#   (e.g. update to epochs, data path, etc.)\n",
    "#\n",
    "# # Train from scratch (256).\n",
    "# CUDA_VISILE_DEVICES=0 python run.py --mode train --config config/vox-256-finetune.yaml --checkpoint /home/jstaley/pretrained_models_motion_v2/vox-cpk.pth.tar --device_ids 0 --log_dir /home/jstaley/train_logs\n",
    "#\n",
    "\n",
    "# Train from checkpoint.\n",
    "# i.e. run below in a terminal.\n",
    "#\n",
    "# CUDA_VISILE_DEVICES=0 python run.py --mode train --config config/vox-512.yaml --checkpoint /home/jupyter/pretrained_models/vox-cpk.pth.tar --device_ids 0 --log_dir /home/jupyter/train_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m59"
  },
  "kernelspec": {
   "display_name": "Python [conda env:my_pytorch10_py37]",
   "language": "python",
   "name": "conda-env-my_pytorch10_py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
