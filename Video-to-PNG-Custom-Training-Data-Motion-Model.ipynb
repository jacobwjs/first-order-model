{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 18 07:17:16 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jstaley\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "base_path = str(Path.home())\n",
    "print(base_path)\n",
    "\n",
    "# Check if running in Colab or AWS.\n",
    "#\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available bucket (0): deep-learning-datasets-bucket\n",
      "Available bucket (1): detectron2-models-bucket\n",
      "Available bucket (2): gan-models-bucket\n",
      "Available bucket (3): insightface-models-bucket\n",
      "Available bucket (4): motion-models\n",
      "\n",
      "Displaying bucket:  motion-models\n",
      "2020-11-03 05:06:42    0 Bytes first-order-model/\n",
      "2020-11-03 05:06:57    0 Bytes first-order-model/pytorch/\n",
      "2020-11-17 15:28:56    0 Bytes first-order-model/pytorch/.ipynb_checkpoints/\n",
      "2020-11-17 15:47:57    0 Bytes first-order-model/pytorch/log.txt\n",
      "2020-11-17 15:47:55    0 Bytes first-order-model/pytorch/train-vis/\n",
      "2020-11-17 15:47:42    1.7 KiB first-order-model/pytorch/vox-256-finetune.yaml\n",
      "2020-11-03 05:10:01  716.1 MiB first-order-model/pytorch/vox-adv-cpk.pth.tar\n",
      "2020-11-03 05:18:31  695.0 MiB first-order-model/pytorch/vox-cpk.pth.tar\n",
      "2020-11-11 04:16:23    0 Bytes motion-cosegmentation/\n",
      "2020-11-11 04:16:39    0 Bytes motion-cosegmentation/pytorch/\n",
      "2020-11-11 04:18:57  716.3 MiB motion-cosegmentation/pytorch/taichi-10segments.pth.tar\n",
      "2020-11-11 04:18:57  716.4 MiB motion-cosegmentation/pytorch/vox-10segments.pth.tar\n",
      "2020-11-11 04:18:57  696.6 MiB motion-cosegmentation/pytorch/vox-15segments.pth.tar\n",
      "2020-11-11 04:18:57  694.0 MiB motion-cosegmentation/pytorch/vox-5segments.pth.tar\n",
      "\n",
      "Total Objects: 14\n",
      "   Total Size: 4.1 GiB\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# List available buckets\n",
    "#\n",
    "available_buckets = []\n",
    "s3 = boto3.resource('s3')\n",
    "for idx, bucket in enumerate(s3.buckets.all()):\n",
    "    print(\"Available bucket (%d): %s\" % (idx, bucket.name))\n",
    "    available_buckets.append(bucket.name)\n",
    "\n",
    "# Interested in bucket with pre-trained models.\n",
    "#\n",
    "bucket_name = available_buckets[4]\n",
    "print(\"\\nDisplaying bucket: \", bucket_name)\n",
    "\n",
    "!aws s3 ls s3://$bucket_name --recursive --human-readable --summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounting bucket:  motion-models\n",
      "path to model:  /home/jstaley/pretrained_models_motion_v2/vox-cpk.pth.tar\n"
     ]
    }
   ],
   "source": [
    "# Create a directory and mount bucket.\n",
    "#\n",
    "print(\"Mounting bucket: \", bucket_name)\n",
    "\n",
    "local_path_to_motion_weights_dir = f'{base_path}/pretrained_models_motion_v2' \n",
    "!mkdir -p $local_path_to_motion_weights_dir\n",
    "\n",
    "model_to_mount = '/first-order-model/pytorch'\n",
    "model_name = 'vox-cpk.pth.tar'\n",
    "path_motion_weights = f'{local_path_to_motion_weights_dir}/{model_name}'\n",
    "\n",
    "print(\"path to model: \", path_motion_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket mounted to: /home/jstaley/pretrained_models_motion\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    !s3fs motion-models:/first-order-model/pytorch /content/pretrained_models_motion -o passwd_file=${HOME}/.passwd-s3fs -o umask=0277,uid=0\n",
    "    print(\"Bucket mounted to: /content/pretrained_models_motion\")\n",
    "else:\n",
    "    # AWS\n",
    "    #\n",
    "    # !s3fs gan-models-bucket:/pixel2style2pixel/pytorch /home/ubuntu/pretrained_models_p2p -o passwd_file=${HOME}/.passwd-s3fs -o umask=0277,uid=1000\n",
    "    # print(\"Bucket mounted to: /home/ubuntu/pretrained_models_p2p\")\n",
    "    \n",
    "    # GCP\n",
    "    #\n",
    "    !s3fs motion-models:/first-order-model/pytorch /home/jstaley/pretrained_models_motion_v2 -o passwd_file=${HOME}/.passwd-s3fs -o umask=0277,uid=1001\n",
    "    print(\"Bucket mounted to: /home/jstaley/pretrained_models_motion_v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the training data (i.e. movie clip) and save to PNGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(path, frames, format):\n",
    "    if format == '.mp4':\n",
    "        imageio.mimsave(path, frames)\n",
    "    elif format == '.png':\n",
    "        if os.path.exists(path):\n",
    "            print (\"Warning: skipping video %s\" % os.path.basename(path))\n",
    "            return\n",
    "        else:\n",
    "            os.makedirs(path)\n",
    "        for j, frame in enumerate(frames):\n",
    "            imageio.imsave(os.path.join(path, str(j).zfill(7) + '.png'), frames[j]) \n",
    "    else:\n",
    "        print (\"Unknown format %s\" % format)\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving frames to:  /home/jstaley/assets/pngs_256px/train/id0001#11111111#000000#000000.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define path where video lives, and where frames will be saved.\n",
    "#\n",
    "path_scene1_indonesian_mom_vid = f'{base_path}/assets/tvc_video_crops/Indonesian_scene1_mom_crop.mp4'\n",
    "path_scene1_indonesian_mom_pngs = f'{base_path}/assets/pngs_256px/train/id0001#11111111#000000#000000.mp4'\n",
    "print(\"saving frames to: \", path_scene1_indonesian_mom_pngs)\n",
    "\n",
    "frames_scene1_indonesian_mom = imageio.mimread(path_scene1_indonesian_mom_vid)\n",
    "save(path=path_scene1_indonesian_mom_pngs,\n",
    "     frames=frames_scene1_indonesian_mom,\n",
    "     format='.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving frames to:  /home/jstaley/assets/pngs_256px/train/id0001#22222222#000000#000000.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define path where video lives, and where frames will be saved.\n",
    "#\n",
    "path_scene2_indonesian_mom_vid = f'{base_path}/assets/tvc_video_crops/Indonesian_scene2_mom_crop.mp4'\n",
    "path_scene2_indonesian_mom_pngs = f'{base_path}/assets/pngs_256px/train/id0001#22222222#000000#000000.mp4'\n",
    "print(\"saving frames to: \", path_scene2_indonesian_mom_pngs)\n",
    "\n",
    "frames_scene2_indonesian_mom = imageio.mimread(path_scene2_indonesian_mom_vid)\n",
    "save(path=path_scene2_indonesian_mom_pngs,\n",
    "     frames=frames_scene2_indonesian_mom,\n",
    "     format='.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving frames to:  /home/jstaley/assets/pngs_256px/train/id0002#11111111#000000#000000.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define path where video lives, and where frames will be saved.\n",
    "#\n",
    "path_scene1_indonesian_son_vid = f'{base_path}/assets/tvc_video_crops/Indonesian_scene1_son_crop.mp4'\n",
    "path_scene1_indonesian_son_pngs = f'{base_path}/assets/pngs_256px/train/id0002#11111111#000000#000000.mp4'\n",
    "print(\"saving frames to: \", path_scene1_indonesian_son_pngs)\n",
    "\n",
    "frames_scene1_indonesian_son = imageio.mimread(path_scene1_indonesian_son_vid)\n",
    "save(path=path_scene1_indonesian_son_pngs,\n",
    "     frames=frames_scene1_indonesian_son,\n",
    "     format='.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving frames to:  /home/jstaley/assets/pngs_256px/train/id0002#22222222#000000#000000.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define path where video lives, and where frames will be saved.\n",
    "#\n",
    "path_scene2_indonesian_son_vid = f'{base_path}/assets/tvc_video_crops/Indonesian_scene2_son_crop.mp4'\n",
    "path_scene2_indonesian_son_pngs = f'{base_path}/assets/pngs_256px/train/id0002#22222222#000000#000000.mp4'\n",
    "print(\"saving frames to: \", path_scene2_indonesian_son_pngs)\n",
    "\n",
    "frames_scene2_indonesian_son = imageio.mimread(path_scene2_indonesian_son_vid)\n",
    "save(path=path_scene2_indonesian_son_pngs,\n",
    "     frames=frames_scene2_indonesian_son,\n",
    "     format='.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving frames to:  /home/jstaley/assets/pngs_256px/train/id0002#33333333#000000#000000.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define path where video lives, and where frames will be saved.\n",
    "#\n",
    "path_scene3_indonesian_son_vid = f'{base_path}/assets/tvc_video_crops/Indonesian_scene3_son_crop.mp4'\n",
    "path_scene3_indonesian_son_pngs = f'{base_path}/assets/pngs_256px/train/id0002#33333333#000000#000000.mp4'\n",
    "print(\"saving frames to: \", path_scene3_indonesian_son_pngs)\n",
    "\n",
    "frames_scene3_indonesian_son = imageio.mimread(path_scene3_indonesian_son_vid)\n",
    "save(path=path_scene3_indonesian_son_pngs,\n",
    "     frames=frames_scene3_indonesian_son,\n",
    "     format='.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in terminal\n",
    "# NOTE:\n",
    "# - Assumes config/vox-XXX.yaml has been appropriately updated/written\n",
    "#   (e.g. update to epochs, data path, etc.)\n",
    "#\n",
    "# # Train from scratch.\n",
    "# CUDA_VISILE_DEVICES=0 python run.py --mode train --config config/vox-256-finetune.yaml --checkpoint /home/jstaley/pretrained_models_motion_v2/vox-cpk.pth.tar --device_ids 0 --log_dir /home/jstaley/train_logs\n",
    "#\n",
    "\n",
    "# # Train from checkpoint.\n",
    "CUDA_VISILE_DEVICES=0 python run.py --mode train --config config/vox-256-finetune.yaml --checkpoint /home/jstaley/pretrained_models_motion_v2/vox-cpk.pth.tar --device_ids 0 --log_dir /home/jstaley/train_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_pytorch_p37] *",
   "language": "python",
   "name": "conda-env-my_pytorch_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
